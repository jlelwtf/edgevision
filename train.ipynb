{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from data_generator import DataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    resnet = keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    output = resnet.layers[-1].output\n",
    "    output = keras.layers.Flatten()(output)\n",
    "    resnet = keras.models.Model(inputs=resnet.input, outputs=output)\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=keras.optimizers.RMSprop(lr=1e-5),\n",
    "        metrics=['accuracy', f1, 'mse']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_dataset.csv')\n",
    "df_train = pd.DataFrame()\n",
    "df_val = pd.DataFrame()\n",
    "\n",
    "for idx, group in df.groupby('class'):\n",
    "    train = group.sample(frac=0.8)\n",
    "    val = group.drop(train.index)\n",
    "    df_train = df_train.append(train, ignore_index=True)\n",
    "    df_val = df_val.append(val, ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.01,\n",
    "    zoom_range=[0.9, 1.25],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "def create_aug_gen(generator):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        in_x, in_y = generator[idx]\n",
    "        g_x = image_generator.flow(255*in_x, in_y, batch_size=in_x.shape[0])\n",
    "        x, y = next(g_x)\n",
    "        idx += 1\n",
    "        if idx == len(generator):\n",
    "            idx = 0\n",
    "            generator.on_epoch_end()\n",
    "        yield x/255.0, y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dicts = list(df_train.T.to_dict().values())\n",
    "val_dicts = list(df_val.T.to_dict().values())\n",
    "all_dicts = list(df.T.to_dict().values())\n",
    "\n",
    "data_gen_train = DataGenerator(\n",
    "    train_dicts, \n",
    "    image_dir='data/train_images', \n",
    "    image_size=(224, 224, 3), \n",
    ")\n",
    "\n",
    "aug_data_gen_train = create_aug_gen(data_gen_train)\n",
    "\n",
    "data_gen_full = DataGenerator(\n",
    "    all_dicts, \n",
    "    image_dir='data/train_images', \n",
    "    image_size=(224, 224, 3), \n",
    ")\n",
    "\n",
    "aug_data_gen_full = create_aug_gen(data_gen_full)\n",
    "\n",
    "data_gen_val = DataGenerator(\n",
    "    val_dicts, \n",
    "    image_dir='data/train_images', \n",
    "    image_size=(224, 224, 3), \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit_generator(aug_data_gen_train, epochs=10, validation_data=data_gen_val, steps_per_epoch=len(data_gen_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1218 12:51:56.290606 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1218 12:51:56.321984 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1218 12:51:56.331458 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1218 12:51:56.368114 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1218 12:51:56.369200 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W1218 12:51:56.455394 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W1218 12:51:56.523513 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "W1218 12:52:08.019501 140713021200192 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1218 12:52:08.236140 140713021200192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 213s 4s/step - loss: 0.7482 - acc: 0.7042 - f1: 0.7042 - mean_squared_error: 0.2195\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 210s 3s/step - loss: 0.5912 - acc: 0.7531 - f1: 0.7531 - mean_squared_error: 0.1787\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 207s 3s/step - loss: 0.4836 - acc: 0.7995 - f1: 0.7995 - mean_squared_error: 0.1452\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 195s 3s/step - loss: 0.5017 - acc: 0.7906 - f1: 0.7906 - mean_squared_error: 0.1523\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 179s 3s/step - loss: 0.4879 - acc: 0.7969 - f1: 0.7969 - mean_squared_error: 0.1496\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 178s 3s/step - loss: 0.4579 - acc: 0.8156 - f1: 0.8156 - mean_squared_error: 0.1388\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 178s 3s/step - loss: 0.4088 - acc: 0.8187 - f1: 0.8187 - mean_squared_error: 0.1273\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 181s 3s/step - loss: 0.4049 - acc: 0.8359 - f1: 0.8359 - mean_squared_error: 0.1218\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 178s 3s/step - loss: 0.4531 - acc: 0.8172 - f1: 0.8172 - mean_squared_error: 0.1346\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 178s 3s/step - loss: 0.3718 - acc: 0.8505 - f1: 0.8505 - mean_squared_error: 0.1110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff9ecd4e1d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit_generator(aug_data_gen_full, epochs=10, steps_per_epoch=len(data_gen_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test_dataset.csv')\n",
    "test_df['class'] = test_df['Predicted']\n",
    "test_dicts = list(test_df.T.to_dict().values())\n",
    "test_datagen = DataGenerator(\n",
    "    test_dicts,\n",
    "    image_dir='data/test_images/',\n",
    "    image_size=(224, 224, 3), \n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predict_df = test_df[['Id']]\n",
    "predict_df['Predicted'] = predict.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.to_csv('predicted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
